% Encoding: UTF-8

@InProceedings{Osokin2017,
  author    = {Anton Osokin and Anatole Chessel and Rafael E. Carazo Salas and Federico Vaggi},
  title     = {{GANs} for Biological Image Synthesis},
  booktitle = {2017 {IEEE} International Conference on Computer Vision ({ICCV})},
  year      = {2017},
  publisher = {{IEEE}},
  month     = {oct},
  pages     = {2252-2261},
  doi       = {10.1109/iccv.2017.245},
  abstract  = {In this paper, we propose a novel application of Generative Adversarial Networks (GAN) to the synthesis of cells imaged by fluorescence microscopy. Compared to natural images, cells tend to have a simpler and more geometric global structure that facilitates image generation. However, the correlation between the spatial pattern of different fluorescent proteins reflects important biological functions, and synthesized images have to capture these relationships to be relevant for biological applications. We adapt GANs to the task at hand and propose new models with casual dependencies between image channels that can generate multichannel images, which would be impossible to obtain experimentally. We evaluate our approach using two independent techniques and compare it against sensible baselines. Finally, we demonstrate that by interpolating across the latent space we can mimic the known changes in protein localization that occur through time during the cell cycle, allowing us to predict temporal evolution from static images.},
  crossref  = {Radford2015},
  file      = {:machinelearning/deep/Osokin_GANs_for_Biological_ICCV_2017_paper.pdf:PDF},
  issn      = {2380-7504},
  keywords  = {biomedical optical imaging;cellular biophysics;medical image processing;optical microscopy;proteins;GAN;image channels;multichannel images;cell cycle;static images;biological image synthesis;Generative Adversarial Networks;fluorescence microscopy;natural images;image generation;spatial pattern;synthesized images;biological applications;fluorescent proteins;biological functions;geometric global structure;Proteins;Gallium nitride;Training;Biological system modeling;Generators;Image generation},
}

@Article{Sirinukunwattana2016,
  author    = {Korsuk Sirinukunwattana and Shan{-}e{-}Ahmed Raza and Yee{-}Wah Tsang and David R. J. Snead and Ian A. Cree and Nasir M. Rajpoot},
  title     = {Locality Sensitive Deep Learning for Detection and Classification of Nuclei in Routine Colon Cancer Histology Images},
  journal   = {{IEEE} Transactions on Medical Imaging},
  year      = {2016},
  volume    = {35},
  number    = {5},
  month     = {5},
  pages     = {1196--1206},
  doi       = {10.1109/tmi.2016.2525803},
  abstract  = {Detection and classification of cell nuclei in histopathology images of cancerous tissue stained with the standard hematoxylin and eosin stain is a challenging task due to cellular heterogeneity. Deep learning approaches have been shown to produce encouraging results on histopathology images in various studies. In this paper, we propose a Spatially Constrained Convolutional Neural Network (SC-CNN) to perform nucleus detection. SC-CNN regresses the likelihood of a pixel being the center of a nucleus, where high probability values are spatially constrained to locate in the vicinity of the centers of nuclei. For classification of nuclei, we propose a novel Neighboring Ensemble Predictor (NEP) coupled with CNN to more accurately predict the class label of detected cell nuclei. The proposed approaches for detection and classification do not require segmentation of nuclei. We have evaluated them on a large dataset of colorectal adenocarcinoma images, consisting of more than 20,000 annotated nuclei belonging to four different classes. Our results show that the joint detection and classification of the proposed SC-CNN and NEP produces the highest average F1 score as compared to other recently published approaches. Prospectively, the proposed methods could offer benefit to pathology practice in terms of quantitative analysis of tissue constituents in whole-slide images, and potentially lead to a better understanding of cancer.},
  file      = {:machinelearning/deep/tmi2016_ks.pdf:PDF},
  keywords  = {Esemble, Histology, SC-CNN, NEP, Neighboring, Prediction, Machine Learning, Deep Learning, Journalclub},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@Misc{Raza2018a,
  author        = {Shan{-}e{-}Ahmed Raza and Linda Cheung and Muhammad Shaban and Simon Graham and David B. A. Epstein and Stella Pelengaris and Michael Khan and Nasir M. Rajpoot},
  title         = {Micro-Net: {A} unified model for segmentation of various objects in microscopy images},
  date          = {2018},
  doi           = {10.1016/j.media.2018.12.003},
  eprint        = {1804.08145},
  eprinttype    = {arXiv},
  url           = {1804.08145},
  abstract      = {Object segmentation and structure localization are important steps in automated image analysis pipelines for microscopy images. We present a convolution neural network (CNN) based deep learning architecture for segmentation of objects in microscopy images. The proposed network can be used to segment cells, nuclei and glands in fluorescence microscopy and histology images after slight tuning of its parameters. It trains itself at multiple resolutions of the input image, connects the intermediate layers for better localization and context and generates the output using multi-resolution deconvolution filters. The extra convolutional layers which bypass the max-pooling operation allow the network to train for variable input intensities and object size and make it robust to noisy data. We compare our results on publicly available data sets and show that the proposed network outperforms the state-of-the-art.},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/corr/abs-1804-08145},
  file          = {:machinelearning/deep/Raza2018 - Micro Net_ a Unified Model for Segmentation of Various Objects in Microscopy Images.pdf:PDF},
  timestamp     = {Mon, 13 Aug 2018 16:48:32 +0200},
}

@Article{Haberl2018,
  author   = {Haberl, Matthias G. and Churas, Christopher and Tindall, Lucas and Boassa, Daniela and Phan, Sébastien and Bushong, Eric A. and Madany, Matthew and Akay, Raffi and Deerinck, Thomas J. and Peltier, Steven T. and Ellisman, Mark H.},
  title    = {CDeep3M--Plug-and-Play cloud-based deep learning for image segmentation},
  issn     = {1548-7105},
  number   = {9},
  pages    = {677--680},
  url      = {https://doi.org/10.1038/s41592-018-0106-z},
  volume   = {15},
  abstract = {As biomedical imaging datasets expand, deep neural networks are considered vital for image processing, yet community access is still limited by setting up complex computational environments and availability of high-performance computing resources. We address these bottlenecks with CDeep3M, a ready-to-use image segmentation solution employing a cloud-based deep convolutional neural network. We benchmark CDeep3M on large and complex two-dimensional and three-dimensional imaging datasets from light, X-ray, and electron microscopy.},
  file     = {:machinelearning/deep/haberl2018.pdf:PDF},
  groups   = {[andreg:]},
  journal  = {Nature Methods},
  month    = sep,
  refid    = {Haberl2018},
  year     = {2018},
}

@Article{Lewicki2003,
  author    = {Grzegorz Lewicki and G. Marino},
  title     = {Approximation by Superpositions of a Sigmoidal Function},
  journal   = {Zeitschrift für Analysis und ihre Anwendungen},
  year      = {2003},
  pages     = {463--470},
  doi       = {10.4171/zaa/1156},
  file      = {:machinelearning/deep/lewicki2003.pdf:PDF},
  publisher = {European Mathematical Publishing House},
}

@InCollection{Krizhevsky2012,
  author    = {Alex Krizhevsky and Ilya Sutskever and Geoffrey E. Hinton},
  title     = {{ImageNet} classification with deep convolutional neural networks},
  booktitle = {Advances in Neural Information Processing Systems 25},
  year      = {2012},
  editor    = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
  publisher = {Curran Associates, Inc.},
  pages     = {1097--1105},
  url       = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf},
  file      = {:machinelearning/deep/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf:PDF},
}

@Article{Xu2016,
  author    = {Jun Xu and Lei Xiang and Qingshan Liu and Hannah Gilmore and Jianzhong Wu and Jinghai Tang and Anant Madabhushi},
  title     = {Stacked Sparse Autoencoder ({SSAE}) for Nuclei Detection on Breast Cancer Histopathology Images},
  journal   = {{IEEE} Transactions on Medical Imaging},
  year      = {2016},
  volume    = {35},
  number    = {1},
  month     = {jan},
  pages     = {119--130},
  doi       = {10.1109/tmi.2015.2458702},
  file      = {:machinelearning/deep/xu2016.pdf:PDF},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@Article{Hinton2006,
  author    = {Hinton, G. E. and Salakhutdinov, R. R.},
  title     = {Reducing the Dimensionality of Data with Neural Networks},
  journal   = {Science},
  year      = {2006},
  volume    = {313},
  number    = {5786},
  pages     = {504--507},
  issn      = {0036-8075},
  doi       = {10.1126/science.1127647},
  eprint    = {http://science.sciencemag.org/content/313/5786/504.full.pdf},
  url       = {http://science.sciencemag.org/content/313/5786/504},
  abstract  = {High-dimensional data can be converted to low-dimensional codes by training a multilayer neural network with a small central layer to reconstruct high-dimensional input vectors. Gradient descent can be used for fine-tuning the weights in such {\textquotedblleft}autoencoder{\textquotedblright} networks, but this works well only if the initial weights are close to a good solution. We describe an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data.},
  file      = {:machinelearning/deep/science.pdf:PDF},
  keywords  = {Autoencoder, ANN},
  publisher = {American Association for the Advancement of Science},
}

@Misc{Zeiler2012,
  author        = {Matthew D. Zeiler},
  title         = {ADADELTA: An Adaptive Learning Rate Method},
  date          = {2012},
  eprint        = {1212.5701},
  eprintclass   = {cs.LG},
  eprinttype    = {arXiv},
  abstract      = {We present a novel per-dimension learning rate method for gradient descent called ADADELTA. The method dynamically adapts over time using only first order information and has minimal computational overhead beyond vanilla stochastic gradient descent. The method requires no manual tuning of a learning rate and appears robust to noisy gradient information, different model architecture choices, various data modalities and selection of hyperparameters. We show promising results compared to other methods on the MNIST digit classification task using a single machine and on a large scale voice dataset in a distributed cluster environment.},
  archiveprefix = {arXiv},
  file          = {:http\://arxiv.org/pdf/1212.5701v1:PDF;:machinelearning/optimizer/1212.5701.pdf:PDF},
  keywords      = {cs.LG},
}

@Misc{Radford2015,
  author      = {Alec Radford and Luke Metz and Soumith Chintala},
  title       = {Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks},
  date        = {2015-11-19},
  eprint      = {http://arxiv.org/abs/1511.06434v2},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  abstract    = {In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.},
  file        = {:http\://arxiv.org/pdf/1511.06434v2:PDF;:machinelearning/deep/Radford2015.pdf:PDF},
  keywords    = {cs.LG, cs.CV},
}

@Article{Ounkomol2018,
  author    = {Chawin Ounkomol and Sharmishtaa Seshamani and Mary M. Maleckar and Forrest Collman and Gregory R. Johnson},
  title     = {Label-free prediction of three-dimensional fluorescence images from transmitted-light microscopy},
  journal   = {Nature Methods},
  year      = {2018},
  volume    = {15},
  number    = {11},
  month     = {sep},
  pages     = {917--920},
  doi       = {10.1038/s41592-018-0111-2},
  abstract  = {Understanding cells as integrated systems is central to modern biology. Although fluorescence microscopy can resolve subcellular structure in living cells, it is expensive, is slow, and can damage cells. We present a label-free method for predicting three-dimensional fluorescence directly from transmittedlight images and demonstrate that it can be used to generate multi-structure, integrated images. The method can also predict immunofluorescence (IF) from electron micrograph (EM) inputs, extending the potential applications.},
  file      = {:machinelearning/deep/Label-free prediction of three-dimensional fluorescence images from transmitted-light microscopy.pdf:PDF},
  keywords  = {Deep, learning, label-free, transmission, inference, self-supervised},
  publisher = {Springer Nature America, Inc},
}

@Misc{Doersch2016,
  author      = {Carl Doersch},
  title       = {Tutorial on Variational Autoencoders},
  date        = {2016-06-19},
  eprint      = {http://arxiv.org/abs/1606.05908v2},
  eprintclass = {stat.ML},
  eprinttype  = {arXiv},
  abstract    = {In just three years, Variational Autoencoders (VAEs) have emerged as one of the most popular approaches to unsupervised learning of complicated distributions. VAEs are appealing because they are built on top of standard function approximators (neural networks), and can be trained with stochastic gradient descent. VAEs have already shown promise in generating many kinds of complicated data, including handwritten digits, faces, house numbers, CIFAR images, physical models of scenes, segmentation, and predicting the future from static images. This tutorial introduces the intuitions behind VAEs, explains the mathematics behind them, and describes some empirical behavior. No prior knowledge of variational Bayesian methods is assumed.},
  file        = {:http\://arxiv.org/pdf/1606.05908v2:PDF},
  keywords    = {stat.ML, cs.LG},
}

@Misc{Kingma2013,
  author      = {Diederik P. Kingma and Max Welling},
  title       = {Auto-Encoding Variational Bayes},
  date        = {2013-12-20},
  eprint      = {http://arxiv.org/abs/1312.6114v10},
  eprintclass = {stat.ML},
  eprinttype  = {arXiv},
  abstract    = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
  file        = {:http\://arxiv.org/pdf/1312.6114v10:PDF;:machinelearning/deep/Kingma2013.pdf:PDF},
  keywords    = {stat.ML, cs.LG},
}

@InCollection{Ronneberger2015,
  author    = {Olaf Ronneberger and Philipp Fischer and Thomas Brox},
  title     = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
  booktitle = {Lecture Notes in Computer Science},
  year      = {2015},
  publisher = {Springer International Publishing},
  pages     = {234--241},
  doi       = {10.1007/978-3-319-24574-4_28},
}

@Article{Russakovsky2015,
  author    = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
  title     = {{ImageNet} Large Scale Visual Recognition Challenge},
  journal   = {International Journal of Computer Vision},
  year      = {2015},
  volume    = {115},
  number    = {3},
  month     = {4},
  pages     = {211--252},
  doi       = {10.1007/s11263-015-0816-y},
  publisher = {Springer Nature},
}

@Article{Caicedo2017,
  author    = {Juan C. Caicedo and Sam Cooper and Florian Heigwer and Scott Warchal and Peng Qiu and Csaba Molnar and Aliaksei S. Vasilevich and Joseph D. Barry and Harmanjit Singh Bansal and Oren Kraus and Mathias Wawer and Lassi Paavolainen and Markus D. Herrmann and Mohammad Rohban and Jane Hung and Holger Hennig and John Concannon and Ian Smith and Paul A. Clemons and Shantanu Singh and Paul Rees and Peter Horvath and Roger G. Linington and Anne E. Carpenter},
  title     = {Data-analysis strategies for image-based cell profiling},
  journal   = {Nature Methods},
  year      = {2017},
  volume    = {14},
  number    = {9},
  month     = {8},
  pages     = {849--863},
  doi       = {10.1038/nmeth.4397},
  file      = {:machinelearning/Data-analysis strategies for image-based cell profiling.pdf:PDF},
  publisher = {Springer Nature},
}

@Article{Schubert2006,
  author    = {Walter Schubert and Bernd Bonnekoh and Ansgar J. Pommer and Lars Philipsen and Raik Böckelmann and Yanina Malykh and Harald Gollnick and Manuela Friedenberger and Marcus Bode and Andreas W. M. Dress},
  title     = {Analyzing proteome topology and function by automated multidimensional fluorescence microscopy},
  journal   = {Nature Biotechnology},
  year      = {2006},
  volume    = {24},
  number    = {10},
  month     = {oct},
  pages     = {1270--1278},
  doi       = {10.1038/nbt1250},
  publisher = {Springer Nature},
}

@Article{Goltsev2018,
  author    = {Yury Goltsev and Nikolay Samusik and Julia Kennedy-Darling and Salil Bhate and Matthew Hale and Gustavo Vazquez and Sarah Black and Garry P. Nolan},
  title     = {Deep Profiling of Mouse Splenic Architecture with {CODEX} Multiplexed Imaging},
  journal   = {Cell},
  year      = {2018},
  volume    = {174},
  number    = {4},
  month     = {8},
  pages     = {968--981},
  doi       = {10.1016/j.cell.2018.07.010},
  publisher = {Elsevier {BV}},
}

@Article{Gerdes2013,
  author    = {M. J. Gerdes and C. J. Sevinsky and A. Sood and S. Adak and M. O. Bello and A. Bordwell and A. Can and A. Corwin and S. Dinn and R. J. Filkins and D. Hollman and V. Kamath and S. Kaanumalle and K. Kenny and M. Larsen and M. Lazare and Q. Li and C. Lowes and C. C. McCulloch and E. McDonough and M. C. Montalto and Z. Pang and J. Rittscher and A. Santamaria-Pang and B. D. Sarachan and M. L. Seel and A. Seppo and K. Shaikh and Y. Sui and J. Zhang and F. Ginty},
  title     = {Highly multiplexed single-cell analysis of formalin-fixed, paraffin-embedded cancer tissue},
  journal   = {Proceedings of the National Academy of Sciences},
  year      = {2013},
  volume    = {110},
  number    = {29},
  month     = {7},
  pages     = {11982--11987},
  doi       = {10.1073/pnas.1300136110},
  publisher = {Proceedings of the National Academy of Sciences},
}

@InProceedings{Berthold2007,
  author    = {Michael R. Berthold and Nicolas Cebron and Fabian Dill and Thomas R. Gabriel and Tobias K\"{o}tter and Thorsten Meinl and Peter Ohl and Christoph Sieb and Kilian Thiel and Bernd Wiswedel},
  title     = {{KNIME}: The {K}onstanz {I}nformation {M}iner},
  booktitle = {Studies in Classification, Data Analysis, and Knowledge Organization (GfKL 2007)},
  year      = {2007},
  publisher = {Springer},
  isbn      = {978-3-540-78239-1},
  issn      = {1431-8814},
}

@Article{Carpenter2006,
  author   = {Carpenter, Anne E. and Jones, Thouis R. and Lamprecht, Michael R. and Clarke, Colin and Kang, In Han and Friman, Ola and Guertin, David A. and Chang, Joo Han and Lindquist, Robert A. and Moffat, Jason and Golland, Polina and Sabatini, David M.},
  title    = {CellProfiler: image analysis software for identifying and quantifying cell phenotypes},
  journal  = {Genome Biology},
  year     = {2006},
  volume   = {7},
  number   = {10},
  month    = {8},
  pages    = {R100},
  issn     = {1474-760X},
  doi      = {10.1186/gb-2006-7-10-r100},
  url      = {https://doi.org/10.1186/gb-2006-7-10-r100},
  abstract = {Biologists can now prepare and image thousands of samples per day using automation, enabling chemical screens and functional genomics (for example, using RNA interference). Here we describe the first free, open-source system designed for flexible, high-throughput cell image analysis, CellProfiler. CellProfiler can address a variety of biological questions quantitatively, including standard assays (for example, cell count, size, per-cell protein levels) and complex morphological assays (for example, cell/organelle shape or subcellular patterns of DNA or protein staining).},
  day      = {31},
}

@Misc{Raza2018,
  author      = {Shan E. Ahmed Raza and Khalid AbdulJabbar and Mariam Jamal-Hanjani and Selvaraju Veeriah and John Le Quesne and Charles Swanton and Yinyin Yuan},
  title       = {Deconvolving convolution neural network for cell detection},
  date        = {2018-06-18},
  eprint      = {http://arxiv.org/abs/1806.06970v1},
  eprintclass = {cs.CV},
  eprinttype  = {arXiv},
  abstract    = {Automatic cell detection in histology images is a challenging task due to varying size, shape and features of cells and stain variations across a large cohort. Conventional deep learning methods regress the probability of each pixel belonging to the centre of a cell followed by detection of local maxima. We present deconvolution as an alternate approach to local maxima detection. The ground truth points are convolved with a mapping filter to generate artifical labels. A convolutional neural network (CNN) is modified to convolve it's output with the same mapping filter and is trained for the mapped labels. Output of the trained CNN is then deconvolved to generate points as cell detection. We compare our method with state-of-the-art deep learning approaches where the results show that the proposed approach detects cells with comparatively high precision and F1-score.},
  file        = {:http\://arxiv.org/pdf/1806.06970v1:PDF},
  keywords    = {cs.CV},
}

@Article{Zhao2018,
  author    = {Yan-Jie Zhao and Jian Zhang and Feng Shi and Zhi-Ping Hu and Jiang-Ping Wu and Guang-Jiang Wu and Rui-Bin Wang and Quan Zhou and Hong Chang and Ying-Nan Li and Qing-Kun Song},
  title     = {Expression of {PD}-1 on {CD}4$\mathplus$ Tumor-Infiltrating Lymphocytes in Tumor Microenvironment Associated with Pathological Characteristics of Breast Cancer},
  journal   = {Journal of Immunology Research},
  year      = {2018},
  volume    = {2018},
  month     = {jul},
  pages     = {1--8},
  doi       = {10.1155/2018/5690258},
  publisher = {Hindawi Limited},
}

@Article{Diana2016,
  author    = {Angela Diana and Lai Mun Wang and Zenobia D'Costa and Paul Allen and Abul Azad and Michael A. Silva and Zahir Soonawalla and Stanley Liu and W. Gillies McKenna and Ruth J. Muschel and Emmanouil Fokas},
  title     = {Prognostic value, localization and correlation of {PD}-1/{PD}-L1, {CD}8 and {FOXP}3 with the desmoplastic stroma in pancreatic ductal adenocarcinoma},
  journal   = {Oncotarget},
  year      = {2016},
  volume    = {7},
  number    = {27},
  month     = {1},
  doi       = {10.18632/oncotarget.10038},
  abstract  = {We examined the prognostic value of programmed cell death-1 (PD-1) and its ligand (PD-L1) together with CD8+ tumor-infiltrating lymphocytes (TILs) and FOXP3+ Tregs in resectable pancreatic ductal adenocarcinoma (PDAC) samples treated with adjuvant chemotherapy. Whole-mount FFPE tissue sections from 145 pancreatectomies were immunohistochemically stained for PD-1, PD-L1, CD8 and FOXP3. Their expression was correlated with clinicopathological characteristics, and overall survival (OS), progression-free survival (PFS), local progression-free survival (LPFS) and distant metastases free-survival (DMFS), in the context of stroma density (haematoxylin-eosin) and activity (alpha-smooth muscle actin) and in regard to intratumoral lymphoid aggregates. The median OS was 21 months after a mean follow-up of 20 months (range, 2-69 months). In multivariate analysis, high PD-1+ TILs expression was associated with better OS (p = 0.049), LPFS (p = 0.017) and DMFS (p = 0.021). Similar findings were observed for CD8+ TILs, whereas FOXP3 and PD-L1 lacked prognostic significance. Although TIL distribution was heterogeneous, tumors of high stroma density had higher infiltration of CD8+ TILs than loose density stroma and vice versa (p < 0.001), whereas no correlation was found with stromal activity. Sixty (41.4%) tumors contained lymphoid aggregates and the presence of PD-1+ TILs was associated with better OS (p = 0.030), LPFS (p = 0.025) and DMFS (p = 0.033), whereas CD8+ TILs only correlated with superior LPFS (p = 0.039). PD-1+ and CD8+ TILs constitute independent prognostic markers in patients with PDAC treated with adjuvant chemotherapy. Our study provides important insight on the role of PD-1/PD-L1 in the context of desmoplastic stroma and could help guide future immunotherapies in PDAC.},
  file      = {:U\:/phd/literatur/immunology/oncotarget-07-40992.pdf:PDF},
  publisher = {Impact Journals, {LLC}},
}

@Article{Wagner2019,
  author    = {Marek Wagner and Shigeo Koyasu},
  title     = {Cancer Immunoediting by Innate Lymphoid Cells},
  journal   = {Trends in Immunology},
  year      = {2019},
  volume    = {40},
  number    = {5},
  month     = {may},
  pages     = {415--430},
  doi       = {10.1016/j.it.2019.03.004},
  publisher = {Elsevier {BV}},
}

@Misc{Goldsborough2017,
  author    = {Peter Goldsborough and Nick Pawlowski and Juan C Caicedo and Shantanu Singh and Anne Carpenter},
  title     = {{CytoGAN}: Generative Modeling of Cell Images},
  year      = {2017},
  month     = {12},
  doi       = {10.1101/227645},
  publisher = {Cold Spring Harbor Laboratory},
}

@InProceedings{Reiss2019,
  author    = {Sandy Reiß and Stefan Tomiuk and Jutta Kollet and Jan Drewes and Wolfgang Brück and Melanie Jungblut and Andreas Bosio},
  title     = {Characterization and classifıcation of glioblastoma multiforme using the novel multiparametric cyclic immunofluorescence analysis system MACSima},
  booktitle = {Proceedings of the American Association for Cancer Research},
  year      = {2019},
  abstract  = {Glioblastoma multiforme (GBM), a highly malignant, non-curative brain tumor of the primary central nervous system, has been subclassifıed in the past years in several distinct subtypes using a multitude of analysis methods. Here, we introduce the MACSima™ imaging platform which allows for fully automated, multiparametric, cyclic immunofluorescence analysis of specimens with hundreds of antibodies. We apply this method to characterize and classify glioblastomas according to published classifıcation schemes and identify novel glioblastoma specifıc markers. Glioblastoma xenografts derived from primary tumors were dissociated to single cells using the Tumor Dissociation Kit, human and the gentleMACS™ Octo Dissociator (Miltenyi Biotec). Single cells were analyzed for cell surface marker expression by flow cytometry (MACSQuant Analyzer 10) including 371 directly conjugated antibodies (MACS Marker Screen, Miltenyi Biotec). A ranking was applied according to the percentage of positive cells and the stain index, leading to a selection of 96 markers for characterization of eight primary glioblastoma using the MACSima™ imaging platform. Cryosections were fıxed by acetone and each specimen was exposed to 96 fluorescent labeled antibodies by cycles of antibody reaction, image acquisition and erasure of signal. The 2D image stacks were analyzed for antigen quantifıcation and pattern recognition using both, pixel and segmented single-cell data. The detection of previously published markers, such as PDGFR, Olig2, p16, p53, Synaptophysin, CD44, Nestin, Podoplanin, GFAP, MET, Hes-1 and EGFR was used to subclassify the glioblastomas according to i) Motomura (Motomura et al., 2012) into Oligodendrocyte Precursor (OPC), Differentiated Oligodendrocyte (DOC), Astrocytic Mesenchymal (AsMes) or Mixed subtype, and ii) Verhaak (Verhaak et al., 2010) into Proneural, Neural, Classical, or Mesenchymal subtype. The analysis of well-established glioblastoma marker partially already used in CAR T cell based clinical trials such as EGFRvIII, HER2, or IL-13R2 revealed a broad inter- and intratumor diversity of expression. Infıltrating immune cells were present in most of the tumors, but showed varying percentages. Finally, segmentation, clustering, and correlation analysis allowed for identifıcation of new marker which might be used for a more robust classifıcation of glioblastomas. In summary, our analysis using the {MACSima™} imaging platform reveals a high heterogeneity of protein expression in glioblastomas along with the ability to deeper classify the diverse tumors and identify novel markers that allow selective detection of tumor cells for their potential use in immunotherapy.},
}

@Article{Hsu2018,
  author    = {Joy Hsu and Jonathan J. Hodgins and Malvika Marathe and Chris J. Nicolai and Marie-Claude Bourgeois-Daigneault and Troy N. Trevino and Camillia S. Azimi and Amit K. Scheer and Haley E. Randolph and Thornton W. Thompson and Lily Zhang and Alexandre Iannello and Nikhita Mathur and Karen E. Jardine and Georgia A. Kirn and John C. Bell and Michael W. McBurney and David H. Raulet and Michele Ardolino},
  title     = {Contribution of {NK} cells to immunotherapy mediated by {PD}-1/{PD}-L1 blockade},
  journal   = {Journal of Clinical Investigation},
  year      = {2018},
  volume    = {128},
  number    = {10},
  month     = {sep},
  pages     = {4654--4668},
  doi       = {10.1172/jci99317},
  publisher = {American Society for Clinical Investigation},
}

@Article{Ishida1992,
  author   = {Ishida, Y. and Agata, Y. and Shibahara, K. and Honjo, T.},
  title    = {Induced expression of PD-1, a novel member of the immunoglobulin gene superfamily, upon programmed cell death},
  issn     = {1460-2075},
  language = {eng},
  number   = {1396582},
  pages    = {3887--3895},
  url      = {https://www.ncbi.nlm.nih.gov/pmc/PMC556898/},
  volume   = {11},
  abstract = {The classical type of programmed cell death is characterized by its dependence on de novo RNA and protein synthesis and morphological features of apoptosis. We confirmed that stimulated 2B4.11 (a murine T-cell hybridoma) and interleukin-3 (IL-3)-deprived LyD9 (a murine haematopoietic progenitor cell line) died by the classical type of programmed cell death. Assuming that common biochemical pathways might be involved in the deaths of 2B4.11 and LyD9, we isolated the PD-1 gene, a novel member of the immunoglobulin gene superfamily, by using subtractive hybridization technique. The predicted PD-1 protein has a variant form of the consensus sequence found in cytoplasmic tails of signal transducing polypeptides associated with immune recognition receptors. The PD-1 gene was activated in both stimulated 2B4.11 and IL-3-deprived LyD9 cells, but not in other death-induced cell lines that did not show the characteristic features of the classical programmed cell death. Expression of the PD-1 mRNA in mouse was restricted to the thymus and increased when thymocyte death was augmented by in vivo injection of anti-CD3 antibody. These results suggest that activation of the PD-1 gene may be involved in the classical type of programmed cell death.},
  comment  = {1396582[pmid]
PMC556898[pmcid]},
  database = {PubMed},
  groups   = {andreg:6},
  journal  = {The EMBO journal},
  month    = nov,
  year     = {1992},
}

@Article{Wang2014,
  author    = {C. Wang and K. B. Thudium and M. Han and X.-T. Wang and H. Huang and D. Feingersh and C. Garcia and Y. Wu and M. Kuhne and M. Srinivasan and S. Singh and S. Wong and N. Garner and H. Leblanc and R. T. Bunch and D. Blanset and M. J. Selby and A. J. Korman},
  title     = {In Vitro Characterization of the Anti-{PD}-1 Antibody Nivolumab, {BMS}-936558, and In Vivo Toxicology in Non-Human Primates},
  journal   = {Cancer Immunology Research},
  year      = {2014},
  volume    = {2},
  number    = {9},
  month     = {may},
  pages     = {846--856},
  doi       = {10.1158/2326-6066.cir-14-0040},
  publisher = {American Association for Cancer Research ({AACR})},
}

@Article{Foppen2015,
  author    = {M. H. Geukes Foppen and M. Donia and I. M. Svane and J. B. A. G. Haanen},
  title     = {Tumor-infiltrating lymphocytes for the treatment of metastatic cancer},
  journal   = {Molecular Oncology},
  year      = {2015},
  volume    = {9},
  number    = {10},
  month     = {oct},
  pages     = {1918--1935},
  doi       = {10.1016/j.molonc.2015.10.018},
  file      = {:U\:/phd/literatur/immunology/MOL2-9-1918.pdf:PDF},
  publisher = {Wiley},
}

@Article{Schindelin2012,
  author    = {Johannes Schindelin and Ignacio Arganda-Carreras and Erwin Frise and Verena Kaynig and Mark Longair and Tobias Pietzsch and Stephan Preibisch and Curtis Rueden and Stephan Saalfeld and Benjamin Schmid and Jean-Yves Tinevez and Daniel James White and Volker Hartenstein and Kevin Eliceiri and Pavel Tomancak and Albert Cardona},
  title     = {Fiji: an open-source platform for biological-image analysis},
  journal   = {Nature Methods},
  year      = {2012},
  volume    = {9},
  number    = {7},
  month     = {6},
  pages     = {676--682},
  doi       = {10.1038/nmeth.2019},
  publisher = {Springer Science and Business Media {LLC}},
}

@Conference{Sommer2011,
  author    = {Christoph Sommer and Strähle, C. and Ullrich Köthe and Fred A. Hamprecht},
  title     = {ilastik: Interactive Learning and Segmentation Toolkit},
  booktitle = {Eighth IEEE International Symposium on Biomedical Imaging (ISBI 2011).Proceedings},
  year      = {2011},
  note      = {1},
  pages     = {230-233},
  doi       = {10.1109/ISBI.2011.5872394},
  abstract  = {Segmentation is the process of partitioning digital images into meaningful regions. The analysis of biological high content images often requires segmentation as a first step. We propose ilastik as an easy-to-use tool which allows the user without expertise in image processing to perform segmentation and classification in a unified way. ilastik learns from labels provided by the user through a convenient mouse interface. Based on these labels, ilastik infers a problem specific segmentation. A random forest classifier is used in the learning step, in which each pixel's neighborhood is characterized by a set of generic (nonlinear) features. ilastik supports up to three spatial plus one spectral dimension and makes use of all dimensions in the feature calculation. ilastik provides realtime feedback that enables the user to interactively refine the segmentation result and hence further fine-tune the classifier. An uncertainty measure guides the user to ambiguous regions in the images. Real time performance is achieved by multi-threading which fully exploits the capabilities of modern multi-core machines. Once a classifier has been trained on a set of representative images, it can be exported and used to automatically process a very large number of images (e.g. using the CellProfiler pipeline). ilastik is an open source project and released under the BSD license at www.ilastik.org.},
}

@Book{Fowler2002,
  author    = {Fowler, Martin},
  title     = {Patterns of Enterprise Application Architecture},
  year      = {2002},
  publisher = {Addison-Wesley Longman Publishing Co., Inc.},
  isbn      = {0321127420},
  address   = {Boston, MA, USA},
}

@Article{Demsar2013,
  author  = {Janez Dem\v{s}ar and Toma\v{z} Curk and Ale\v{s} Erjavec and \v{C}rt Gorup and Toma\v{z} Ho\v{c}evar and Mitar Milutinovi\v{c} and Martin Mo\v{z}ina and Matija Polajnar and Marko Toplak and An\v{z}e Stari\v{c} and Miha \v{S}tajdohar and Lan Umek and Lan \v{Z}agar and Jure \v{Z}bontar and Marinka \v{Z}itnik and Bla\v{z} Zupan},
  title   = {Orange: Data Mining Toolbox in Python},
  journal = {Journal of Machine Learning Research},
  year    = {2013},
  volume  = {14},
  pages   = {2349-2353},
  url     = {http://jmlr.org/papers/v14/demsar13a.html},
}

@Misc{Campagnola2019,
  author = {Luke Campagnola},
  title  = {PyQtGraph Scientific Graphics and GUI Library for Python},
  year   = {2019},
  url    = {http://www.pyqtgraph.org/},
}

@Article{Maaten2008,
  author  = {Maaten, Laurens van der and Hinton, Geoffrey},
  title   = {Visualizing data using t-SNE},
  journal = {Journal of machine learning research},
  year    = {2008},
  volume  = {9},
  number  = {Nov},
  pages   = {2579--2605},
  file    = {Paper:machinelearning/Visualizing High-Dimensional Data Using t-SNE.pdf:PDF},
}

@Article{Hendry2017,
  author    = {Shona Hendry and Roberto Salgado and Thomas Gevaert and Prudence A. Russell and Tom John and Bibhusal Thapa and Michael Christie and Koen van de Vijver and M.V. Estrada and Paula I. Gonzalez-Ericsson and Melinda Sanders and Benjamin Solomon and Cinzia Solinas and Gert G.G.M. Van den Eynden and Yves Allory and Matthias Preusser and Johannes Hainfellner and Giancarlo Pruneri and Andrea Vingiani and Sandra Demaria and Fraser Symmans and Paolo Nuciforo and Laura Comerma and E.A. Thompson and Sunil Lakhani and Seong-Rim Kim and Stuart Schnitt and Cecile Colpaert and Christos Sotiriou and Stefan J. Scherer and Michail Ignatiadis and Sunil Badve and Robert H. Pierce and Giuseppe Viale and Nicolas Sirtaine and Frederique Penault-Llorca and Tomohagu Sugie and Susan Fineberg and Soonmyung Paik and Ashok Srinivasan and Andrea Richardson and Yihong Wang and Ewa Chmielik and Jane Brock and Douglas B. Johnson and Justin Balko and Stephan Wienert and Veerle Bossuyt and Stefan Michiels and Nils Ternes and Nicole Burchardi and Stephen J. Luen and Peter Savas and Frederick Klauschen and Peter H. Watson and Brad H. Nelson and Carmen Criscitiello and Sandra O'Toole and Denis Larsimont and Roland de Wind and Giuseppe Curigliano and Fabrice Andr{\'{e}} and Magali Lacroix-Triki and Mark van de Vijver and Federico Rojo and Giuseppe Floris and Shahinaz Bedri and Joseph Sparano and David Rimm and Torsten Nielsen and Zuzana Kos and Stephen Hewitt and Baljit Singh and Gelareh Farshid and Sibylle Loibl and Kimberly H. Allison and Nadine Tung and Sylvia Adams and Karen Willard-Gallo and Hugo M. Horlings and Leena Gandhi and Andre Moreira and Fred Hirsch and Maria V. Dieci and Maria Urbanowicz and Iva Brcic and Konstanty Korski and Fabien Gaire and Hartmut Koeppen and Amy Lo and Jennifer Giltnane and Marlon C. Rebelatto and Keith E. Steele and Jiping Zha and Kenneth Emancipator and Jonathan W. Juco and Carsten Denkert and Jorge Reis-Filho and Sherene Loi and Stephen B. Fox},
  title     = {Assessing Tumor-Infiltrating Lymphocytes in Solid Tumors},
  doi       = {10.1097/pap.0000000000000161},
  number    = {6},
  pages     = {311--335},
  volume    = {24},
  abstract  = {Assessment of the immune response to tumors is growing in importance as the prognostic implications of this response are increasingly recognized, and as immunotherapies are evaluated and implemented in different tumor types. However, many different approaches can be used to assess and describe the immune response, which limits efforts at implementation as a routine clinical biomarker. In part 1 of this review, we have proposed a standardized methodology to assess tumor infiltrating lymphocytes (TILs) in solid tumors, based on the International Immuno-Oncology Biomarkers Working Group guidelines for invasive breast carcinoma. In part 2 of this review, we discuss the available evidence for the prognostic and predictive value of TILs in common solid tumors, including carcinomas of the lung, gastrointestinal tract, genitourinary system, gynecological system, and head and neck, as well as primary brain tumors, mesothelioma and melanoma. The particularities and different emphases in TIL assessment in different tumor types are discussed. The standardized methodology we propose can be adapted to different tumor types and may be used as a standard against which other approaches can be compared. Standardization of TIL assessment will help clinicians, researchers and pathologists to conclusively evaluate the utility of this simple biomarker in the current era of immunotherapy.},
  journal   = {Advances In Anatomic Pathology},
  month     = {nov},
  publisher = {Ovid Technologies (Wolters Kluwer Health)},
  year      = {2017},
}

@Article{Idos2020,
  author    = "Gregory E. Idos and Janet Kwok and Nirupama Bonthala and Lynn Kysh and Stephen B. Gruber and Chenxu Qu",
  title     = "The Prognostic Implications of Tumor Infiltrating Lymphocytes in Colorectal Cancer: A Systematic Review and Meta-Analysis",
  journal   = "Scientific Reports",
  year      = "2020",
  volume    = "10",
  number    = "1",
  month     = "February",
  doi       = "10.1038/s41598-020-60255-4",
  publisher = "Springer Science and Business Media {LLC}",
}

@Article{Santoiemma2015,
  author    = "Phillip P Santoiemma and Daniel J Powell",
  title     = "Tumor infiltrating lymphocytes in ovarian cancer",
  journal   = "Cancer Biology {\&} Therapy",
  year      = "2015",
  volume    = "16",
  number    = "6",
  pages     = "807-820",
  month     = "April",
  doi       = "10.1080/15384047.2015.1040960",
  publisher = "Informa {UK} Limited",
}

@article{kinkhabwalaMACSimaImagingCyclic2022,
  title = {{{MACSima}} Imaging Cyclic Staining ({{MICS}}) Technology Reveals Combinatorial Target Pairs for {{CAR T}}~Cell~Treatment of Solid Tumors},
  author = {Kinkhabwala, Ali and Herbel, Christoph and Pankratz, Jennifer and Yushchenko, Dmytro A. and Rüberg, Silvia and Praveen, Paurush and Reiß, Sandy and Rodriguez, Federico Carlos and Schäfer, Daniel and Kollet, Jutta and Dittmer, Vera and Martinez-Osuna, Manuel and Minnerup, Lara and Reinhard, Claudia and Dzionek, Andrzej and Rockel, Thomas Dino and Borbe, Stefan and Büscher, Martin and Krieg, Jürgen and Nederlof, Michel and Jungblut, Melanie and Eckardt, Dominik and Hardt, Olaf and Dose, Christian and Schumann, Eik and Peters, Ralf-Peter and Miltenyi, Stefan and Schmitz, Jürgen and Müller, Werner and Bosio, Andreas},
  date = {2022-02-03},
  journaltitle = {Scientific Reports},
  shortjournal = {Sci Rep},
  volume = {12},
  number = {1},
  eprint = {35115587},
  eprinttype = {pmid},
  pages = {1911},
  issn = {2045-2322},
  doi = {10.1038/s41598-022-05841-4},
  abstract = {Many critical advances in research utilize techniques that combine high-resolution with high-content characterization at the single cell level. We introduce the MICS (MACSima Imaging Cyclic Staining) technology, which enables the immunofluorescent imaging of hundreds of protein targets across a single specimen at subcellular resolution. MICS is based on cycles of staining, imaging, and erasure, using photobleaching of fluorescent labels of recombinant antibodies (REAfinity Antibodies), or release of antibodies (REAlease Antibodies) or their labels (REAdye\_lease Antibodies). Multimarker analysis can identify potential targets for immune therapy against solid tumors. With MICS we analysed human glioblastoma, ovarian and pancreatic carcinoma, and 16 healthy tissues, identifying the pair EPCAM/THY1 as a potential target for chimeric antigen receptor (CAR) T cell therapy for ovarian carcinoma. Using an Adapter CAR T cell approach, we show selective killing of cells only if both markers are expressed. MICS represents a new high-content microscopy methodology widely applicable for personalized medicine.},
  langid = {english},
  pmcid = {PMC8813936},
  keywords = {Biomarkers; Tumor,Cell Death,Cytotoxicity; Immunologic,Epithelial Cell Adhesion Molecule,Fluorescent Antibody Technique,High-Throughput Screening Assays,Humans,Immunotherapy; Adoptive,Neoplasms,Photobleaching,Receptors; Chimeric Antigen,Single-Cell Analysis,T-Lymphocytes,Thy-1 Antigens},
  file = {/home/rikisa/Zotero/storage/Q2LR5PTW/Kinkhabwala et al. - 2022 - MACSima imaging cyclic staining (MICS) technology .pdf}
}



@Comment{jabref-meta: databaseType:biblatex;}

@Comment{jabref-meta: grouping:
0 AllEntriesGroup:;
1 StaticGroup:Markings\;2\;1\;\;\;\;;
2 StaticGroup:[andreg:]\;2\;1\;\;\;\;;
2 StaticGroup:andreg:6\;2\;1\;\;\;\;;
}
